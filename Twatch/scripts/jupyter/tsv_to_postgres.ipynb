{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Panacea Lab COVID-19 dataset to Postgres\n",
    "[Raw data source](https://github.com/thepanacealab/covid19_twitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# last_stop = 20000000\n",
    "from twitter_auth_info import Auth\n",
    "max_count = -1 # For debugging\n",
    "LOOKUP_TWEETS_LIMIT = 100 # https://developer.twitter.com/en/docs/tweets/post-and-engage/api-reference/get-statuses-lookup\n",
    "runtime_log = open(\"tsv_to_postgres_log\", \"w\")\n",
    "error_log = open(\"tsv_to_postgres_errors_log\", \"w\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "from datetime import datetime\n",
    "\n",
    "def get_time_now():\n",
    "    now = datetime.now()\n",
    "    return now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "from twarc import Twarc\n",
    "twarc = Twarc(Auth.api['key'], Auth.api['secret'], Auth.access['key'], Auth.access['secret'])\n",
    "from postgres import Postgres\n",
    "from psycopg2.errors import UniqueViolation\n",
    "db = Postgres(url='postgresql://postgres:postgres@localhost:5432/twatch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class ChunkStatus(Enum):\n",
    "    NOT_STARTED = 0\n",
    "    INCOMPLETE = 1\n",
    "    COMPLETE = 2\n",
    "\n",
    "    \n",
    "class ChunkManager():\n",
    "    def __init__(self):\n",
    "        self.chunks = []\n",
    "        self.incomplete_chunks = []\n",
    "        self.load_chunks()\n",
    "        \n",
    "        \n",
    "    def load_chunks(self):\n",
    "        with open('processed_chunks', 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for l in lines:\n",
    "                if l[0] != '~':\n",
    "                    self.chunks.append(int(l))\n",
    "                else:\n",
    "                    self.incomplete_chunks.append(int(l[1:]))\n",
    "\n",
    "        \n",
    "        \n",
    "    def save_chunks(self):\n",
    "        with open('processed_chunks', 'w') as chunk_file:\n",
    "            for c in self.chunks:\n",
    "                chunk_file.write(\"{}\\n\".format(c))\n",
    "            for c in self.incomplete_chunks:\n",
    "                chunk_file.write(\"~{}\\n\".format(c))\n",
    "                \n",
    "               \n",
    "    def add_completed_chunk(self, chunk_id):\n",
    "        if chunk_id not in self.chunks:\n",
    "            self.chunks.append(chunk_id)\n",
    "        if chunk_id in self.incomplete_chunks:\n",
    "            self.incomplete_chunks.remove(chunk_id)\n",
    "        self.save_chunks()\n",
    "        \n",
    "        \n",
    "    def add_incomplete_chunk(self, chunk_id):\n",
    "        if chunk_id in self.chunks:\n",
    "            raise Exception(\"Chunck already completed\")\n",
    "        if chunk_id not in self.incomplete_chunks:\n",
    "            self.incomplete_chunks.append(chunk_id)\n",
    "        self.save_chunks()\n",
    "                \n",
    "            \n",
    "    def check_chunk(self, chunk_id):\n",
    "        if chunk_id in self.chunks:\n",
    "            return ChunkStatus.COMPLETE\n",
    "        elif chunk_id in self.incomplete_chunks:\n",
    "            return ChunkStatus.INCOMPLETE\n",
    "        else:\n",
    "            return ChunkStatus.NOT_STARTED\n",
    "        \n",
    "                \n",
    "    def print_chunks(self):\n",
    "        print(\"Completed chunks: {}\".format(str(self.chunks)))\n",
    "        print(\"Incomplete chunks: {}\".format(str(self.incomplete_chunks)))\n",
    "              \n",
    "              \n",
    "    def __del__(self):\n",
    "        self.save_chunks()\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk #3: 426419/1000000 tweets processed, 39268 new tweets saved\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:twarc:caught read timeout: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=31)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk #6: 803143/1000000 tweets processed, 79583 new tweets saved\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:twarc:caught read timeout: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=31)\n",
      "ERROR:twarc:caught connection error HTTPSConnectionPool(host='api.twitter.com', port=443): Max retries exceeded with url: /1.1/statuses/lookup.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f965c271ca0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')) on 1 try\n",
      "ERROR:twarc:caught connection error HTTPSConnectionPool(host='api.twitter.com', port=443): Max retries exceeded with url: /1.1/statuses/lookup.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f965c271670>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')) on 2 try\n",
      "ERROR:twarc:caught connection error HTTPSConnectionPool(host='api.twitter.com', port=443): Max retries exceeded with url: /1.1/statuses/lookup.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f965c14aac0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')) on 3 try\n",
      "ERROR:twarc:caught connection error HTTPSConnectionPool(host='api.twitter.com', port=443): Max retries exceeded with url: /1.1/statuses/lookup.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f965c2ca940>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')) on 4 try\n",
      "ERROR:twarc:caught connection error HTTPSConnectionPool(host='api.twitter.com', port=443): Max retries exceeded with url: /1.1/statuses/lookup.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f965f766a30>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')) on 5 try\n",
      "ERROR:twarc:caught connection error HTTPSConnectionPool(host='api.twitter.com', port=443): Max retries exceeded with url: /1.1/statuses/lookup.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f965aafe790>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')) on 6 try\n",
      "ERROR:twarc:caught connection error HTTPSConnectionPool(host='api.twitter.com', port=443): Max retries exceeded with url: /1.1/statuses/lookup.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f965c9256a0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')) on 7 try\n",
      "ERROR:twarc:caught connection error HTTPSConnectionPool(host='api.twitter.com', port=443): Max retries exceeded with url: /1.1/statuses/lookup.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f965c29ce20>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')) on 8 try\n",
      "ERROR:twarc:caught connection error HTTPSConnectionPool(host='api.twitter.com', port=443): Max retries exceeded with url: /1.1/statuses/lookup.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f965c43f640>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')) on 9 try\n",
      "ERROR:twarc:caught connection error HTTPSConnectionPool(host='api.twitter.com', port=443): Max retries exceeded with url: /1.1/statuses/lookup.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f965c445310>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')) on 10 try\n",
      "ERROR:twarc:caught connection error HTTPSConnectionPool(host='api.twitter.com', port=443): Max retries exceeded with url: /1.1/statuses/lookup.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f965c445d30>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')) on 11 try\n",
      "ERROR:twarc:caught connection error HTTPSConnectionPool(host='api.twitter.com', port=443): Max retries exceeded with url: /1.1/statuses/lookup.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f965b998940>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')) on 12 try\n",
      "ERROR:twarc:caught connection error HTTPSConnectionPool(host='api.twitter.com', port=443): Max retries exceeded with url: /1.1/statuses/lookup.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f965c6063d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')) on 13 try\n",
      "ERROR:twarc:caught connection error HTTPSConnectionPool(host='api.twitter.com', port=443): Max retries exceeded with url: /1.1/statuses/lookup.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f965c601130>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')) on 14 try\n",
      "ERROR:twarc:caught connection error HTTPSConnectionPool(host='api.twitter.com', port=443): Max retries exceeded with url: /1.1/statuses/lookup.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f965c601d30>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')) on 15 try\n",
      "ERROR:twarc:caught connection error HTTPSConnectionPool(host='api.twitter.com', port=443): Max retries exceeded with url: /1.1/statuses/lookup.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f965c601fa0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')) on 16 try\n"
     ]
    }
   ],
   "source": [
    "buffer = []\n",
    "num_tweets_saved = 0\n",
    "total = 0\n",
    "chunksize = 10 ** 6\n",
    "chunk_manager = ChunkManager()\n",
    "\n",
    "df = pd.read_csv('data/full_dataset.tsv', sep=\"\\t\", iterator=True, chunksize=chunksize)\n",
    "\n",
    "for chunk_id, in_df in enumerate(df):\n",
    "    last_stop = 0\n",
    "    if chunk_manager.check_chunk(chunk_id) == ChunkStatus.COMPLETE:\n",
    "        print(\"Chunk #{} is completed.\".format(chunk_id), end='\\r', flush=True)\n",
    "        continue\n",
    "    if chunk_manager.check_chunk(chunk_id) == ChunkStatus.INCOMPLETE:\n",
    "        print(\"Chunk #{} is partially completed.\".format(chunk_id))\n",
    "        chunk_test_distance = int(chunksize / LOOKUP_TWEETS_LIMIT)\n",
    "        test_row_ids = [i * chunk_test_distance for i in range(LOOKUP_TWEETS_LIMIT)]\n",
    "        test_results = [False for i in range(LOOKUP_TWEETS_LIMIT)]\n",
    "        for i, test_row_id in enumerate(test_row_ids):\n",
    "            row = in_df.iloc[test_row_id]\n",
    "            test_tweet = db.one(''' SELECT * FROM tweets WHERE tweet_id = %s''', [str(row.tweet_id)])\n",
    "            test_tweet_incr = db.one(''' SELECT * FROM tweets_incr WHERE tweet_id = %s''', [str(row.tweet_id)])\n",
    "            if test_tweet is not None or test_tweet_incr is not None:\n",
    "                test_results[i] = True\n",
    "        last_stop_id = len(test_results) - 1\n",
    "        while last_stop_id > 0:\n",
    "            if test_results[last_stop_id]:\n",
    "                break\n",
    "            else:\n",
    "                last_stop_id -= 1\n",
    "        last_stop = test_row_ids[last_stop_id]\n",
    "        print(\"Resuming from {}\".format(last_stop))\n",
    "                   \n",
    "    try:\n",
    "        print(\"Reading chunk {}.\".format(chunk_id), end=\"\\r\", flush=True)\n",
    "        in_df = in_df[in_df['lang']=='en']\n",
    "        for row in in_df.itertuples():\n",
    "            if row.Index < last_stop:\n",
    "                continue\n",
    "            if max_count > 0 and row.Index > max_count:\n",
    "                break\n",
    "\n",
    "#             test_retweet = db.one(''' SELECT * FROM retweets WHERE tweet_id = %s''', [str(row.tweet_id)])\n",
    "#             test_retweet_incr = db.one(''' SELECT * FROM retweets_incr WHERE tweet_id = %s''', [str(row.tweet_id)])\n",
    "#             if test_retweet is not None or test_retweet_incr is not None:\n",
    "    #             print(test_retweet)\n",
    "#                 continue\n",
    "\n",
    "            test_tweet = db.one(''' SELECT * FROM tweets WHERE tweet_id = %s''', [str(row.tweet_id)])\n",
    "            test_tweet_incr = db.one(''' SELECT * FROM tweets_incr WHERE tweet_id = %s''', [str(row.tweet_id)])\n",
    "            if test_tweet is not None or test_tweet_incr is not None:\n",
    "    #             print(test_tweet)\n",
    "                continue\n",
    "\n",
    "\n",
    "            buffer.append(row.tweet_id)\n",
    "\n",
    "            if len(buffer) < LOOKUP_TWEETS_LIMIT:\n",
    "                continue\n",
    "            else:\n",
    "                for tweet in twarc.hydrate(buffer):\n",
    "                    try:\n",
    "                        if tweet['retweet_count'] + tweet['favorite_count'] < 10:\n",
    "                            continue\n",
    "                        user = tweet['user']\n",
    "                        unix = int(datetime.strptime(tweet['created_at'], '%a %b %d %H:%M:%S %z %Y').timestamp())\n",
    "                        if tweet.get('retweeted_status') is not None:\n",
    "#                             db.run(''' INSERT INTO retweets_incr(root_tweet_id,tweet_id,unix,user_followers_count)\n",
    "#                                        VALUES (%s,%s,%s,%s)''', (tweet['retweeted_status']['id_str'],tweet['id_str'],unix,user['followers_count']))\n",
    "                            continue\n",
    "                        else:\n",
    "                            db.run(''' INSERT INTO tweets_incr(tweet_id,unix,user_id,num_retweets,num_favourites,\n",
    "                                       reply_parent_id,text,location)\n",
    "                                      VALUES (%s,%s,%s,%s,%s,%s,%s,%s)''', \n",
    "                                        (tweet[\"id_str\"],unix,user[\"id_str\"],tweet[\"retweet_count\"],tweet[\"favorite_count\"],\n",
    "                                          tweet[\"in_reply_to_status_id\"] if tweet[\"in_reply_to_status_id\"] is not None else -1,\n",
    "                                          tweet[\"full_text\"],str(tweet[\"coordinates\"])\n",
    "                                    ))\n",
    "                        try:\n",
    "                            db.run(''' INSERT INTO users(user_id,user_name,user_screen_name,user_location,user_followers_count,user_friends_count,user_is_verified,user_profile_image_url)\n",
    "                                        VALUES (%s,%s,%s,%s,%s,%s,%s,%s) ON CONFLICT (user_id) DO UPDATE\n",
    "                                        SET user_name = excluded.user_name,\n",
    "                                            user_screen_name = excluded.user_screen_name,\n",
    "                                            user_followers_count = excluded.user_followers_count,\n",
    "                                            user_friends_count = excluded.user_friends_count,\n",
    "                                            user_is_verified = excluded.user_is_verified,\n",
    "                                            user_profile_image_url = excluded.user_profile_image_url;\n",
    "                                    ''', (user['id_str'],user['name'],user['screen_name'],user['location'],user['followers_count'],user['friends_count'],user['verified'],user['profile_image_url_https']))\n",
    "                        except UniqueViolation:\n",
    "                            pass\n",
    "                        except Exception as e:\n",
    "                            raise e    \n",
    "                        finally:              \n",
    "                            num_tweets_saved += 1\n",
    "                    except UniqueViolation:\n",
    "                        pass\n",
    "                    except Exception as e:\n",
    "                        print(\"Encountered error at line {}\".format(row.Index))\n",
    "                        error_log.write(\"====={}=====\\n\".format(get_time_now()))\n",
    "                        error_log.write(\"Encountered error when processing line {}\\n\".format(row.Index))\n",
    "                        error_log.write(\"Number of tweets saved: {}\\n\".format(num_tweets_saved))\n",
    "                        error_log.write(str(e) + \"\\n\")\n",
    "                        error_log.write(\"\\n=============================\\n\")\n",
    "                        error_log.flush()\n",
    "                    finally:\n",
    "                        runtime_log.write(\"===== {} =====\\n\".format(get_time_now()))\n",
    "                        runtime_log.write(\"Stored tweets until line {} to DB, {} tweets saved so far.\\n\".format(row.Index, num_tweets_saved))\n",
    "                        runtime_log.write(\"=============================\\n\")\n",
    "                        runtime_log.flush()\n",
    "                        print(\"Chunk #{}: {}/{} tweets processed, {} new tweets saved\".format(chunk_id ,row.Index % chunksize, chunksize, num_tweets_saved), end=\"\\r\", flush=True)\n",
    "                        buffer.clear()\n",
    "    except:\n",
    "        print(\"Chunk {} interrupted.\".format(chunk_id))\n",
    "        chunk_manager.add_incomplete_chunk(chunk_id)\n",
    "        raise\n",
    "    chunk_manager.add_completed_chunk(chunk_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
